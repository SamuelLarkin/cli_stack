version: "3"

env:
  BASH_COMPLETION_D: "{{.HOME}}/.local/share/bash-completion/completions"
  BASH_RC_D: "{{.HOME}}/.bashrc.d"
  BIN_DIR: "{{.HOME}}/.local/bin"
  INSTALL_DIR: "{{.HOME}}/.local"

tasks:
  default:
    deps:
      - ollama
      - xidel

  ollama:
    desc: >
      [oLLaMa](https://github.com/ollama/ollama):
      Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.
      Note: we can't simply to `go install github.com/ollama/ollama@latest` or we won't get the GPU speed up libraries.
    cmds:
      - |
        curl \
          --create-dirs --fail --location \
          --output "ollama-$VERSION-linux-amd64.tgz" \
        "https://github.com/ollama/ollama/releases/download/$VERSION/ollama-linux-amd64.tgz"
      - defer: rm "ollama-$VERSION-linux-amd64.tgz"
      - tar xf "ollama-$VERSION-linux-amd64.tgz" --directory={{.INSTALL_DIR}}
    dir: $HOME/tmp
    env:
      VERSION: v0.5.7
    generates:
      - "{{.BIN_DIR}}/ollama"
    status:
      - which ollama

  xidel:
    desc: >
      [forgit](https://github.com/wfxr/forgit):
      A utility tool powered by fzf for using git interactively.
    cmds:
      - |
        curl \
          --create-dirs --fail --location \
          --output "xidel-$VERSION.linux64.tar.gz" \
          "https://sourceforge.net/projects/videlibri/files/Xidel/Xidel%20$VERSION/xidel-$VERSION.linux64.tar.gz/download"
      - defer: rm "xidel-$VERSION.linux64.tar.gz"
      - tar xf "xidel-$VERSION.linux64.tar.gz"
      - defer: rm changelog install.sh readme.txt
      - chmod u+x xidel
      - mv xidel "{{.BIN_DIR}}"
    dir: $HOME/tmp
    env:
      VERSION: 0.9.8
    generates:
      - "{{.BIN_DIR}}/xidel"
    status:
      - which xidel
